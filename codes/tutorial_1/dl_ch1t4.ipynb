{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "found-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [4.209015  , 6.0251656 , 6.586659  , 1.0785204 , 5.323591,   2.9644287, 8.885769  , 9.895647  ,  6.464806  , 0.18034637, 1.2534696]\n",
    "x = [34.552039 , 74.45411  , 80.987488 ,  3.458197 , 56.4778655, 26.98163  , 95.79415  , 106.228316 , 61.169422 , 1.089516 , 8.962632]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wired-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 34.5520,  74.4541,  80.9875,   3.4582,  56.4779,  26.9816,  95.7942,\n",
       "        106.2283,  61.1694,   1.0895,   8.9626])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.tensor(y)\n",
    "x = torch.tensor(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "computational-librarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blind-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(yy, y):\n",
    "    squared_diffs = (yy - y)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "according-premises",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'Optimizer',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_multi_tensor',\n",
       " 'functional',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "dir(optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "automatic-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-5\n",
    "optimizer = optim.SGD([params], lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accredited-leonard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9.3147e-01, -9.0416e-04], requires_grad=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy = model(x, *params)\n",
    "loss = loss_fn(yy, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "differential-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9400, -0.0039], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_u = x * 0.1\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "yy = model(x_u, *params)\n",
    "loss = loss_fn(yy, y)\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "wound-heritage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, x, y):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        yy = model(x, *params)\n",
    "        loss = loss_fn(yy, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 500 == 0:\n",
    "            print('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "meaning-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 0.263147\n",
      "Epoch 1000, Loss 0.262983\n",
      "Epoch 1500, Loss 0.262982\n",
      "Epoch 2000, Loss 0.262982\n",
      "Epoch 2500, Loss 0.262982\n",
      "Epoch 3000, Loss 0.262982\n",
      "Epoch 3500, Loss 0.262982\n",
      "Epoch 4000, Loss 0.262982\n",
      "Epoch 4500, Loss 0.262982\n",
      "Epoch 5000, Loss 0.262982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8410, 0.5997], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-2\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    x = x_u,\n",
    "    y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suited-policy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 0.265097\n",
      "Epoch 1000, Loss 0.262982\n",
      "Epoch 1500, Loss 0.262982\n",
      "Epoch 2000, Loss 0.262982\n",
      "Epoch 2500, Loss 0.262983\n",
      "Epoch 3000, Loss 0.262982\n",
      "Epoch 3500, Loss 0.262982\n",
      "Epoch 4000, Loss 0.262982\n",
      "Epoch 4500, Loss 0.262982\n",
      "Epoch 5000, Loss 0.262982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0841, 0.5997], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-1\n",
    "optimizer = optim.Adam([params], lr=learning_rate)\n",
    "\n",
    "training_loop(\n",
    "    n_epochs = 5000,\n",
    "    optimizer = optimizer,\n",
    "    params = params,\n",
    "    x = x,\n",
    "    y = y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
